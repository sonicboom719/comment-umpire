import streamlit as st
import os
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import re
from datetime import datetime
import time
from dotenv import load_dotenv
from openai import OpenAI
import json
import streamlit.components.v1 as components

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ã‚³ãƒ¡ãƒ³ãƒˆå¯©åˆ¤",
    page_icon="ğŸ’¬",
    layout="wide"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®å¹…ã‚’åºƒã’ã‚‹ */
    section[data-testid="stSidebar"] {
        width: 400px !important;
    }
    section[data-testid="stSidebar"] > div {
        width: 400px !important;
    }
    /* ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ãƒãƒ¼ã‚¸ãƒ³èª¿æ•´ */
    .main > div {
        padding-right: 1rem;
    }
    .comment-container {
        padding: 10px 0;
        border-bottom: 1px solid #e0e0e0;
    }
    .load-more-container {
        padding: 20px;
        text-align: center;
    }
    .analysis-result {
        background-color: #f0f2f6;
        padding: 15px;
        border-radius: 10px;
        margin-bottom: 15px;
    }
    .category-badge {
        display: inline-block;
        padding: 4px 8px;
        border-radius: 4px;
        font-size: 14px;
        font-weight: bold;
        margin-bottom: 10px;
    }
    .category-çš®è‚‰ { background-color: #FF5722; color: white; }
    .category-å˜²ç¬‘ { background-color: #E91E63; color: white; }
    .category-æ„Ÿæƒ³ { background-color: #4CAF50; color: white; }
    .category-æ„è¦‹ { background-color: #2196F3; color: white; }
    .category-ã‚¢ãƒ‰ãƒã‚¤ã‚¹ { background-color: #00BCD4; color: white; }
    .category-æ‰¹åˆ¤ { background-color: #FF9800; color: white; }
    .category-èª¹è¬—ä¸­å‚· { background-color: #F44336; color: white; }
    .category-æ‚ªå£ { background-color: #9C27B0; color: white; }
    .category-ä¾®è¾± { background-color: #D32F2F; color: white; }
    .category-ä¸Šã‹ã‚‰ç›®ç·š { background-color: #795548; color: white; }
    .category-è«–ç‚¹ã™ã‚Šæ›¿ãˆ { background-color: #607D8B; color: white; }
    .category-æ”»æ’ƒçš„ { background-color: #B71C1C; color: white; }
    .category-è³è³› { background-color: #8BC34A; color: white; }
    .category-æ„Ÿè¬ { background-color: #FFC107; color: black; }
    .category-æƒ…å ±æä¾› { background-color: #3F51B5; color: white; }
    .category-å•é¡Œæèµ· { background-color: #FF5722; color: white; }
    .category-æ­£è«– { background-color: #009688; color: white; }
    .category-å·®åˆ¥çš„ { background-color: #212121; color: white; }
    .category-å…±æ„Ÿ { background-color: #FFB6C1; color: black; }
    
</style>
""", unsafe_allow_html=True)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'comments' not in st.session_state:
    st.session_state.comments = []
if 'next_page_token' not in st.session_state:
    st.session_state.next_page_token = None
if 'video_id' not in st.session_state:
    st.session_state.video_id = None
if 'replies' not in st.session_state:
    st.session_state.replies = {}
if 'loading_replies' not in st.session_state:
    st.session_state.loading_replies = set()
if 'is_loading_more' not in st.session_state:
    st.session_state.is_loading_more = False
if 'displayed_count' not in st.session_state:
    st.session_state.displayed_count = 100
if 'analyzed_comment' not in st.session_state:
    st.session_state.analyzed_comment = None
if 'analyzing' not in st.session_state:
    st.session_state.analyzing = False
if 'loading_show_more' not in st.session_state:
    st.session_state.loading_show_more = False
if 'button_clicked' not in st.session_state:
    st.session_state.button_clicked = False
if 'pending_analysis' not in st.session_state:
    st.session_state.pending_analysis = None
if 'video_info' not in st.session_state:
    st.session_state.video_info = None

# YouTube API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
@st.cache_resource
def get_youtube_client():
    api_key = os.environ.get('YOUTUBE_API_KEY')
    if not api_key:
        st.error("YouTube API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•° YOUTUBE_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    return build('youtube', 'v3', developerKey=api_key)

# OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
@st.cache_resource
def get_openai_client():
    api_key = os.environ.get('OPENAI_API_KEY')
    if not api_key:
        return None
    return OpenAI(api_key=api_key)

# YouTube URLã‹ã‚‰Video IDã‚’æŠ½å‡º
def extract_video_id(url):
    patterns = [
        r'(?:youtube\.com\/watch\?v=|youtu\.be\/)([^&\n?]+)',
        r'youtube\.com\/embed\/([^&\n?]+)',
        r'youtube\.com\/v\/([^&\n?]+)'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    return None

# ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
def fetch_comments(video_id, page_token=None, max_results=100):
    youtube = get_youtube_client()
    
    try:
        request = youtube.commentThreads().list(
            part="snippet",
            videoId=video_id,
            maxResults=max_results,
            pageToken=page_token,
            order="relevance"
        )
        response = request.execute()
        
        comments = []
        for item in response.get('items', []):
            comment = item['snippet']['topLevelComment']['snippet']
            comments.append({
                'id': item['id'],
                'text': comment['textDisplay'],
                'text_original': comment['textOriginal'],
                'author': comment['authorDisplayName'],
                'author_image': comment['authorProfileImageUrl'],
                'published_at': comment['publishedAt'],
                'like_count': comment.get('likeCount', 0),
                'reply_count': item['snippet']['totalReplyCount']
            })
        
        return comments, response.get('nextPageToken')
    
    except HttpError as e:
        st.error(f"YouTube API ã‚¨ãƒ©ãƒ¼: {e}")
        return [], None

# è¿”ä¿¡ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
def fetch_replies(parent_id):
    youtube = get_youtube_client()
    
    try:
        request = youtube.comments().list(
            part="snippet",
            parentId=parent_id,
            maxResults=100
        )
        response = request.execute()
        
        replies = []
        for item in response.get('items', []):
            comment = item['snippet']
            replies.append({
                'id': item['id'],
                'text': comment['textDisplay'],
                'text_original': comment['textOriginal'],
                'author': comment['authorDisplayName'],
                'author_image': comment['authorProfileImageUrl'],
                'published_at': comment['publishedAt'],
                'like_count': comment.get('likeCount', 0)
            })
        
        return replies
    
    except HttpError as e:
        st.error(f"è¿”ä¿¡å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []

# æ—¥æ™‚ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
def format_datetime(dt_str):
    dt = datetime.fromisoformat(dt_str.replace('Z', '+00:00'))
    return dt.strftime('%Y/%m/%d %H:%M')

# å‹•ç”»æƒ…å ±ã‚’å–å¾—
def fetch_video_info(video_id):
    youtube = get_youtube_client()
    
    try:
        request = youtube.videos().list(
            part="snippet",
            id=video_id
        )
        response = request.execute()
        
        if response.get('items'):
            video = response['items'][0]['snippet']
            return {
                'title': video['title'],
                'channel_title': video['channelTitle'],
                'channel_id': video['channelId'],
                'published_at': video['publishedAt'],
                'thumbnail': video['thumbnails']['medium']['url']
            }
        return None
    
    except HttpError as e:
        st.error(f"å‹•ç”»æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# ãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±ã‚’å–å¾—
def fetch_channel_info(channel_id):
    youtube = get_youtube_client()
    
    try:
        request = youtube.channels().list(
            part="snippet",
            id=channel_id
        )
        response = request.execute()
        
        if response.get('items'):
            channel = response['items'][0]['snippet']
            return {
                'profile_image': channel['thumbnails']['default']['url']
            }
        return None
    
    except HttpError as e:
        st.error(f"ãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# ã‚³ã‚¢ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
def load_core_prompt():
    try:
        with open('core_prompt.txt', 'r', encoding='utf-8') as f:
            return f.read().strip()
    except FileNotFoundError:
        st.error("core_prompt.txtãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return ""
    except Exception as e:
        st.error(f"ã‚³ã‚¢ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return ""

# è¿½åŠ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
def load_additional_prompt():
    try:
        with open('additional_prompt.txt', 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        # ã‚³ãƒ¡ãƒ³ãƒˆè¡Œï¼ˆ#ã§å§‹ã¾ã‚‹è¡Œï¼‰ã¨ç©ºè¡Œã‚’é™¤å»
        additional_lines = []
        for line in lines:
            line = line.strip()
            if line and not line.startswith('#'):
                additional_lines.append(line)
        
        return '\n'.join(additional_lines) if additional_lines else ""
    except FileNotFoundError:
        return ""
    except Exception as e:
        st.warning(f"è¿½åŠ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return ""

# å˜ä¸€ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’åˆ†æ
def analyze_single_comment(comment_text, context_comments=None):
    client = get_openai_client()
    if not client:
        return None
    
    # ã‚³ã‚¢ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã¿
    core_prompt = load_core_prompt()
    if not core_prompt:
        return None
    
    # è¿½åŠ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã¿
    additional_prompt = load_additional_prompt()
    additional_section = f"\n\nã€è¿½åŠ ã®åˆ†ææŒ‡ç¤ºã€‘\n{additional_prompt}" if additional_prompt else ""
    
    # æ–‡è„ˆæƒ…å ±ã‚’æ§‹ç¯‰
    context_section = ""
    if context_comments:
        context_section = "\n\nã€æ–‡è„ˆæƒ…å ±ã€‘\nä»¥ä¸‹ã¯ä¼šè©±ã®æµã‚Œã§ã™ï¼š\n"
        for i, ctx_comment in enumerate(context_comments):
            context_section += f"{i+1}. {ctx_comment['author']}: {ctx_comment['text_original']}\n"
        context_section += "\nåˆ†æå¯¾è±¡ã¯æœ€å¾Œã®ã‚³ãƒ¡ãƒ³ãƒˆã§ã™ã€‚ä¼šè©±ã®æµã‚Œã‚’è€ƒæ…®ã—ã¦åˆ†æã—ã¦ãã ã•ã„ã€‚\n"
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ–‡å­—åˆ—ã‚’ä½¿ç”¨ï¼‰
    prompt = core_prompt.format(
        context_section=context_section,
        comment_text=comment_text,
        additional_section=additional_section
    )

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "ä¸ãˆã‚‰ã‚ŒãŸã‚³ãƒ¡ãƒ³ãƒˆã‚’åˆ†æã—ã€æŒ‡å®šã•ã‚ŒãŸå½¢å¼ã®æœ‰åŠ¹ãªJSONã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚categoryã¯è©²å½“ã™ã‚‹ã‚‚ã®ã‚’è¤‡æ•°é¸æŠå¯èƒ½ã§ã™ï¼ˆé…åˆ—ã§è¿”ã—ã¦ãã ã•ã„ï¼‰ã€‚ã€Œè‰ã€ã€Œwã€ã€Œç¬‘ã€ç­‰ãŒå«ã¾ã‚Œã‚‹å ´åˆã€æ–‡è„ˆã«å¿œã˜ã¦ã€Œå˜²ç¬‘ã€ï¼ˆé¦¬é¹¿ã«ã™ã‚‹æ„å›³ï¼‰ã¾ãŸã¯ã€Œæ„Ÿæƒ³ã€ï¼ˆç´”ç²‹ã«é¢ç™½ãŒã‚‹ï¼‰ã‚’åˆ¤å®šã—ã¦ãã ã•ã„ã€‚ã€Œä¾®è¾±ã€ã¯ç›¸æ‰‹ã‚’è¦‹ä¸‹ã—ãŸã‚Šè»½è”‘ã™ã‚‹è¡¨ç¾ã€ã€Œä¸Šã‹ã‚‰ç›®ç·šã€ã¯å‰ãã†ãªæ…‹åº¦ã‚„é«˜åœ§çš„ãªç‰©è¨€ã„ã€ã€Œè«–ç‚¹ã™ã‚Šæ›¿ãˆã€ã¯æœ¬æ¥ã®è­°é¡Œã‹ã‚‰è©±ã‚’é€¸ã‚‰ã™è¡Œç‚ºã€ã€Œæ”»æ’ƒçš„ã€ã¯æ•µæ„ã‚„æ”»æ’ƒæ€§ã‚’å«ã‚€è¡¨ç¾ã€ã€Œè³è³›ã€ã¯ç§°è³›ã‚„è¤’ã‚ã‚‹è¡¨ç¾ã€ã€Œæ„Ÿè¬ã€ã¯æ„Ÿè¬ã®æ°—æŒã¡ã‚’è¡¨ã™è¡¨ç¾ã€ã€Œæƒ…å ±æä¾›ã€ã¯æ–°ã—ã„æƒ…å ±ã‚„çŸ¥è­˜ã‚’æä¾›ã™ã‚‹å†…å®¹ã€ã€Œå•é¡Œæèµ·ã€ã¯å•é¡Œç‚¹ã‚„èª²é¡Œã‚’æŒ‡æ‘˜ã™ã‚‹å†…å®¹ã€ã€Œæ­£è«–ã€ã¯è«–ç†çš„ã§æ­£å½“æ€§ã®ã‚ã‚‹ä¸»å¼µã€ã€Œå·®åˆ¥çš„ã€ã¯ç‰¹å®šã®å±æ€§ã«åŸºã¥ãåè¦‹ã‚„å·®åˆ¥çš„è¡¨ç¾ã€ã€Œå…±æ„Ÿã€ã¯ä»–è€…ã®æ°—æŒã¡ã‚„çŠ¶æ³ã«å¯¾ã™ã‚‹ç†è§£ã‚„åŒèª¿ã‚’ç¤ºã™è¡¨ç¾ã‚’æŒ‡ã—ã¾ã™ã€‚ä¾‹ãˆã°ã€çš®è‚‰ã‚’è¾¼ã‚ãŸæ„Ÿæƒ³ã®å ´åˆã¯[\"çš®è‚‰\", \"æ„Ÿæƒ³\"]ã®ã‚ˆã†ã«è¤‡æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚explanationã«ã¯ã€å…·ä½“çš„ã«ã‚³ãƒ¡ãƒ³ãƒˆã®ã©ã®éƒ¨åˆ†ãŒãªãœãã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«åˆ†é¡ã•ã‚ŒãŸã®ã‹ã€ä¸€èˆ¬ã®äººã«ã‚‚åˆ†ã‹ã‚Šã‚„ã™ã„æ—¥æœ¬èªã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚æŠ€è¡“çš„ãªç”¨èªï¼ˆJSONã€true/falseç­‰ï¼‰ã¯ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.7,
            max_tokens=1000
        )
        
        content = response.choices[0].message.content.strip()
        return json.loads(content)
        
    except Exception as e:
        st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        return None

# ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¡¨ç¤º
def display_comment(comment, is_reply=False, parent_comment=None, previous_replies=None):
    col1, col2 = st.columns([1, 20])
    
    with col1:
        st.image(comment['author_image'], width=40)
    
    with col2:
        # ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±
        header_html = f"""
        <div style="margin-bottom: 5px;">
            <strong>{comment['author']}</strong>
            <span style="color: #666; font-size: 0.9em;">
                {format_datetime(comment['published_at'])}
            </span>
            <span style="color: #065fd4; font-size: 0.9em;">
                ğŸ‘ {comment['like_count']}
            </span>
        </div>
        """
        st.markdown(header_html, unsafe_allow_html=True)
        
        # ã‚³ãƒ¡ãƒ³ãƒˆæœ¬æ–‡
        st.markdown(comment['text'], unsafe_allow_html=True)
        
        # ãƒœã‚¿ãƒ³ã‚³ãƒ³ãƒ†ãƒŠ
        button_container = st.container()
        with button_container:
            # å¯©åˆ¤ãƒœã‚¿ãƒ³ã¨è¿”ä¿¡ãƒœã‚¿ãƒ³ã‚’é…ç½®
            if not is_reply and comment['reply_count'] > 0:
                # è¿”ä¿¡ãŒã‚ã‚‹å ´åˆã¯ä¸¡æ–¹ã®ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
                col1, col2, col3 = st.columns([1, 2, 10])
                with col1:
                    if st.button("âš–ï¸ å¯©åˆ¤", key=f"judge_{comment['id']}", help="AIã§ã‚³ãƒ¡ãƒ³ãƒˆã‚’åˆ†æ"):
                        # å‰å›ã®çµæœã‚’ã‚¯ãƒªã‚¢ã—ã€ä¿ç•™ä¸­ã®åˆ†æã‚’è¨­å®š
                        st.session_state.analyzed_comment = None
                        st.session_state.analyzing = False
                        st.session_state.pending_analysis = {
                            'comment': comment,
                            'context_comments': None  # è¦ªã‚³ãƒ¡ãƒ³ãƒˆã«ã¯æ–‡è„ˆãªã—
                        }
                        st.rerun()
                
                with col2:
                    if comment['id'] in st.session_state.replies:
                        # è¿”ä¿¡ã‚’éš ã™ãƒœã‚¿ãƒ³
                        if st.button("â–¼ è¿”ä¿¡ã‚’éš ã™", key=f"reply_btn_{comment['id']}"):
                            del st.session_state.replies[comment['id']]
                    else:
                        # è¿”ä¿¡ã‚’è¡¨ç¤ºã™ã‚‹ãƒœã‚¿ãƒ³
                        reply_text = f"â–¶ {comment['reply_count']}ä»¶ã®è¿”ä¿¡"
                        if st.button(reply_text, key=f"reply_btn_{comment['id']}"):
                            st.session_state.loading_replies.add(comment['id'])
                            st.rerun()
            else:
                # è¿”ä¿¡ãŒãªã„å ´åˆã¯å¯©åˆ¤ãƒœã‚¿ãƒ³ã®ã¿
                col1, col2 = st.columns([1, 12])
                with col1:
                    if st.button("âš–ï¸ å¯©åˆ¤", key=f"judge_{comment['id']}", help="AIã§ã‚³ãƒ¡ãƒ³ãƒˆã‚’åˆ†æ"):
                        # è¿”ä¿¡ã‚³ãƒ¡ãƒ³ãƒˆã®å ´åˆã¯æ–‡è„ˆæƒ…å ±ã‚’æ§‹ç¯‰
                        context_comments = None
                        if is_reply and parent_comment:
                            context_comments = [parent_comment]  # è¦ªã‚³ãƒ¡ãƒ³ãƒˆã‚’æœ€åˆã«è¿½åŠ 
                            if previous_replies:
                                context_comments.extend(previous_replies)  # ãã‚Œã¾ã§ã®è¿”ä¿¡ã‚’è¿½åŠ 
                        
                        # å‰å›ã®çµæœã‚’ã‚¯ãƒªã‚¢ã—ã€ä¿ç•™ä¸­ã®åˆ†æã‚’è¨­å®š
                        st.session_state.analyzed_comment = None
                        st.session_state.analyzing = False
                        st.session_state.pending_analysis = {
                            'comment': comment,
                            'context_comments': context_comments
                        }
                        st.rerun()

# HTMLã‚¿ã‚°ã‚’é™¤å»ã™ã‚‹é–¢æ•°
def remove_html_tags(text):
    """HTMLã‚¿ã‚°ã‚’é™¤å»ã—ã¦ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›"""
    import re
    # <br>ã‚¿ã‚°ã‚’æ”¹è¡Œã«å¤‰æ›
    text = re.sub(r'<br\s*/?>', '\n', text, flags=re.IGNORECASE)
    # ãã®ä»–ã®HTMLã‚¿ã‚°ã‚’é™¤å»
    text = re.sub(r'<[^>]+>', '', text)
    return text

# åˆ†æçµæœã‚’è¡¨ç¤º
def display_analysis_result(comment, analysis):
    st.markdown("### ğŸ” ã‚³ãƒ¡ãƒ³ãƒˆåˆ†æçµæœ")
    
    # å…ƒã®ã‚³ãƒ¡ãƒ³ãƒˆè¡¨ç¤º
    with st.expander("åˆ†æå¯¾è±¡ã‚³ãƒ¡ãƒ³ãƒˆ", expanded=True):
        st.markdown(f"**{comment['author']}** - {format_datetime(comment['published_at'])}")
        # HTMLã‚¿ã‚°ã‚’é™¤å»ã—ã¦è¡¨ç¤º
        clean_text = remove_html_tags(comment['text'])
        st.text(clean_text)
    
    # ã‚«ãƒ†ã‚´ãƒªãƒ¼è¡¨ç¤ºï¼ˆè¤‡æ•°å¯¾å¿œãƒ»æ¨ªä¸¦ã³ï¼‰
    categories = analysis['category']
    if isinstance(categories, list):
        # è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªã®å ´åˆ - æ¨ªä¸¦ã³ã§è¡¨ç¤º
        category_html = ""
        for category in categories:
            category_html += f'<span class="category-badge category-{category}" style="margin-right: 8px;">{category}</span>'
        st.markdown(category_html, unsafe_allow_html=True)
    else:
        # å˜ä¸€ã‚«ãƒ†ã‚´ãƒªã®å ´åˆï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
        st.markdown(f'<span class="category-badge category-{categories}">{categories}</span>', unsafe_allow_html=True)
    
    # åè«–ã®åˆ†æ
    if analysis['isCounter']:
        st.markdown("#### ğŸ¯ åè«–ã®è³ªï¼ˆã‚°ãƒ©ãƒãƒ ã®ãƒ’ã‚¨ãƒ©ãƒ«ã‚­ãƒ¼ï¼‰")
        hierarchy = analysis.get('grahamHierarchy', 'è©²å½“ãªã—')
        if hierarchy != 'è©²å½“ãªã—':
            st.info(hierarchy)
    
    # è«–ç†çš„èª¤è¬¬ï¼ˆå˜ä¸€ã®å€¤ï¼‰
    fallacy = analysis.get('logicalFallacy')
    if fallacy and fallacy != 'null':
        st.markdown("#### âš ï¸ æ¤œå‡ºã•ã‚ŒãŸè«–ç†çš„èª¤è¬¬")
        st.warning(fallacy)
    
    # ä¸»å¼µã®å¦¥å½“æ€§
    validity = analysis.get('validityAssessment')
    if validity and validity != 'åˆ¤æ–­å›°é›£':
        st.markdown("#### ğŸ“Š ä¸»å¼µã®å¦¥å½“æ€§")
        if validity == 'é«˜ã„':
            st.success(f"å¦¥å½“æ€§: {validity}")
        elif validity == 'ä¸­ç¨‹åº¦':
            st.info(f"å¦¥å½“æ€§: {validity}")
        elif validity == 'ä½ã„':
            st.error(f"å¦¥å½“æ€§: {validity}")
        
        # å¦¥å½“æ€§ã®ç†ç”±
        validity_reason = analysis.get('validityReason')
        if validity_reason:
            st.markdown(f"**è©•ä¾¡ç†ç”±**: {validity_reason}")
    
    # è©³ç´°ãªèª¬æ˜
    st.markdown("#### ğŸ“ åˆ¤å®šç†ç”±")
    st.markdown(analysis['explanation'])

# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒª
def main():
    st.title("ğŸ’¬ ã‚³ãƒ¡ãƒ³ãƒˆå¯©åˆ¤")
    
    # URLå…¥åŠ›
    url_container = st.container()
    with url_container:
        col1, col2 = st.columns([4, 1], vertical_alignment="bottom")
        with col1:
            url = st.text_input("URL", placeholder="YouTube URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (ä¾‹: https://www.youtube.com/watch?v=...)", key="url_input", label_visibility="collapsed")
        with col2:
            load_button = st.button("ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—", type="primary")
    
    # å‹•ç”»æƒ…å ±è¡¨ç¤ºï¼ˆURLå…¥åŠ›ãƒœãƒƒã‚¯ã‚¹ã®ç›´ä¸‹ï¼‰
    if st.session_state.video_info:
        video_info = st.session_state.video_info
        
        # å‹•ç”»æƒ…å ±ã‚’è¡¨ç¤º
        col1, col2 = st.columns([1, 20])
        with col1:
            if 'profile_image' in video_info:
                st.image(video_info['profile_image'], width=40)
        with col2:
            st.markdown(f"**{video_info['title']}**")
            st.markdown(f"ãƒãƒ£ãƒ³ãƒãƒ«: {video_info['channel_title']}")
    
    # æ–°ã—ã„URLãŒå…¥åŠ›ã•ã‚ŒãŸã‚‰çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
    if load_button and url:
        video_id = extract_video_id(url)
        if video_id:
            if video_id != st.session_state.video_id:
                st.session_state.comments = []
                st.session_state.next_page_token = None
                st.session_state.replies = {}
                st.session_state.video_id = video_id
                st.session_state.displayed_count = 100
                st.session_state.analyzed_comment = None
                st.session_state.video_info = None
            
            # å‹•ç”»æƒ…å ±ã¨ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
            with st.spinner("å‹•ç”»æƒ…å ±ã¨ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ä¸­..."):
                # å‹•ç”»æƒ…å ±ã‚’å–å¾—
                video_info = fetch_video_info(video_id)
                if video_info:
                    # ãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±ã‚‚å–å¾—
                    channel_info = fetch_channel_info(video_info['channel_id'])
                    if channel_info:
                        video_info.update(channel_info)
                    st.session_state.video_info = video_info
                
                # ã‚³ãƒ¡ãƒ³ãƒˆå–å¾—
                comments, next_token = fetch_comments(video_id)
                st.session_state.comments = comments
                st.session_state.next_page_token = next_token
                
                # çŠ¶æ…‹æ›´æ–°å¾Œã«å†æç”»ã‚’å¼·åˆ¶å®Ÿè¡Œ
                st.rerun()
        else:
            st.error("æœ‰åŠ¹ãªYouTube URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    # ä¿ç•™ä¸­ã®åˆ†æã‚’é–‹å§‹
    if st.session_state.pending_analysis:
        pending = st.session_state.pending_analysis
        st.session_state.pending_analysis = None
        st.session_state.analyzing = True
        st.session_state.analyzed_comment = {
            'comment': pending['comment'],
            'analysis': None,
            'context_comments': pending['context_comments']
        }
        st.rerun()
    
    # åˆ†æå‡¦ç†
    if st.session_state.analyzing and st.session_state.analyzed_comment:
        comment_data = st.session_state.analyzed_comment
        if comment_data['analysis'] is None:
            # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¡¨ç¤º
            with st.sidebar:
                st.markdown("### ğŸ” ã‚³ãƒ¡ãƒ³ãƒˆåˆ†æä¸­...")
                with st.spinner("AIãŒã‚³ãƒ¡ãƒ³ãƒˆã‚’åˆ†æã—ã¦ã„ã¾ã™..."):
                    # åˆ†æå®Ÿè¡Œï¼ˆæ–‡è„ˆæƒ…å ±ã‚’å«ã‚ã‚‹ï¼‰
                    analysis = analyze_single_comment(
                        comment_data['comment']['text_original'], 
                        comment_data.get('context_comments')
                    )
                    st.session_state.analyzed_comment['analysis'] = analysis
                    st.session_state.analyzing = False
                    st.rerun()
    
    # è¿”ä¿¡ã®å‹•çš„ãƒ­ãƒ¼ãƒ‰å‡¦ç†
    for comment_id in list(st.session_state.loading_replies):
        if comment_id not in st.session_state.replies:
            replies = fetch_replies(comment_id)
            st.session_state.replies[comment_id] = replies
            st.session_state.loading_replies.remove(comment_id)
            st.rerun()
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ã‚µã‚¤ãƒ‰ãƒãƒ¼
    main_container = st.container()
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«åˆ†æçµæœã‚’è¡¨ç¤º
    with st.sidebar:
        if st.session_state.analyzing:
            # åˆ†æä¸­ã®è¡¨ç¤ºï¼ˆã“ã®éƒ¨åˆ†ã¯ä¸Šã®åˆ†æå‡¦ç†ã§è¡¨ç¤ºã•ã‚Œã‚‹ãŸã‚ã€ã“ã“ã§ã¯ä½•ã‚‚ã—ãªã„ï¼‰
            pass
        elif st.session_state.analyzed_comment and st.session_state.analyzed_comment['analysis']:
            display_analysis_result(
                st.session_state.analyzed_comment['comment'],
                st.session_state.analyzed_comment['analysis']
            )
            
            if st.button("âœ–ï¸ é–‰ã˜ã‚‹"):
                st.session_state.analyzed_comment = None
                st.rerun()
        else:
            st.markdown("### ğŸ“Š ã‚³ãƒ¡ãƒ³ãƒˆåˆ†æ")
            st.info("ã‚³ãƒ¡ãƒ³ãƒˆã®ã€Œå¯©åˆ¤ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€AIã«ã‚ˆã‚‹åˆ†æçµæœãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
            
            # OpenAI APIã‚­ãƒ¼ã®ç¢ºèª
            if not get_openai_client():
                st.warning("OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚åˆ†ææ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    
    # ã‚³ãƒ¡ãƒ³ãƒˆè¡¨ç¤º
    with main_container:
        if st.session_state.comments:
            st.divider()
            
            # è¡¨ç¤ºã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆæ•°ã‚’åˆ¶é™
            comments_to_display = st.session_state.comments[:st.session_state.displayed_count]
            
            for comment in comments_to_display:
                # è¦ªã‚³ãƒ¡ãƒ³ãƒˆè¡¨ç¤º
                with st.container():
                    display_comment(comment)
                    
                    # è¿”ä¿¡è¡¨ç¤º
                    if comment['id'] in st.session_state.replies:
                        # è¿”ä¿¡ç”¨ã®ã‚³ãƒ³ãƒ†ãƒŠã‚’ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆ
                        reply_container = st.container()
                        with reply_container:
                            # Streamlitã®ã‚«ãƒ©ãƒ æ©Ÿèƒ½ã‚’ä½¿ã£ã¦ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆ
                            reply_col1, reply_col2 = st.columns([1, 20])  # 1:20ã®æ¯”ç‡ã§ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆ
                            with reply_col1:
                                # å·¦å´ã¯ç©ºç™½ï¼ˆã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆåŠ¹æœï¼‰
                                st.markdown('<div style="height: 1px; background: #e0e0e0; width: 100%;"></div>', unsafe_allow_html=True)
                            with reply_col2:
                                # å„è¿”ä¿¡ã‚³ãƒ¡ãƒ³ãƒˆ
                                replies = st.session_state.replies[comment['id']]
                                for i, reply in enumerate(replies):
                                    # ãã‚Œã¾ã§ã®è¿”ä¿¡ã‚³ãƒ¡ãƒ³ãƒˆã‚’æ–‡è„ˆã¨ã—ã¦æ¸¡ã™
                                    previous_replies = replies[:i] if i > 0 else None
                                    display_comment(reply, is_reply=True, parent_comment=comment, previous_replies=previous_replies)
                                    if reply != replies[-1]:  # æœ€å¾Œä»¥å¤–ã«å°ã•ã„åŒºåˆ‡ã‚Š
                                        st.markdown('<hr style="margin: 10px 0; border: none; border-top: 1px solid #f0f0f0;">', unsafe_allow_html=True)
                    
                    st.divider()
            
            # ã•ã‚‰ã«è¡¨ç¤ºã™ã‚‹ãƒœã‚¿ãƒ³ï¼ˆçµ±åˆç‰ˆï¼‰
            show_button = (len(st.session_state.comments) > st.session_state.displayed_count or 
                          st.session_state.next_page_token)
            
            if show_button:
                col1, col2, col3 = st.columns([1, 2, 1])
                with col2:
                    if st.button("ã•ã‚‰ã«è¡¨ç¤º", key="unified_load_more", type="primary", use_container_width=True):
                        # ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯æ™‚ã«å³åº§ã«å‡¦ç†
                        if len(st.session_state.comments) > st.session_state.displayed_count:
                            # æ—¢ã«å–å¾—æ¸ˆã¿ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¡¨ç¤º
                            st.session_state.displayed_count += 100
                        elif st.session_state.next_page_token:
                            # æ–°ã—ã„ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
                            new_comments, next_token = fetch_comments(
                                st.session_state.video_id,
                                st.session_state.next_page_token
                            )
                            st.session_state.comments.extend(new_comments)
                            st.session_state.next_page_token = next_token
                            st.session_state.displayed_count += len(new_comments)
            

if __name__ == "__main__":
    main()